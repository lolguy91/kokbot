'use strict';
var __importDefault =
	(this && this.__importDefault) ||
	function (mod) {
		return mod && mod.__esModule ? mod : { default: mod };
	};
Object.defineProperty(exports, '__esModule', { value: true });
exports.nsblob = void 0;
const blake_1 = require('./blake');
const doge_config_1 = require('doge-config');
const fs_1 = __importDefault(require('fs'));
const nodesite_eu_core_1 = __importDefault(require('nodesite.eu-core'));
const path_1 = __importDefault(require('path'));
const serial_async_io_1 = require('serial-async-io');
const hashmap_1 = require('./hashmap');
const config = (0, doge_config_1.getConfig)('nsblob', {
	cache_size_limit: 1 << 28,
	file_size_limit: 1 << 24,
	str_internal_error: 'INTERNAL_ERROR',
	str_not_a_file: 'NOT_A_FILE',
	file_too_large: 'File was too large.',
});
const { file_size_limit } = config.num;
const socket = (0, nodesite_eu_core_1.default)();
class nsblob {
	static gc(max_size = config.num.cache_size_limit) {
		while (
			nsblob.cache.size &&
			nsblob.cache_keys.length &&
			max_size < nsblob.cache_size
		) {
			const key = nsblob.cache_keys.shift();
			if (!key) continue;
			if (nsblob.cache_keys.includes(key)) continue;
			const obj = nsblob.cache.get(key);
			nsblob.cache.delete(key);
			if (!obj) continue;
			cache_size.set(nsblob.cache, nsblob.cache_size - obj.length);
		}
		return nsblob.cache_size;
	}
	static cache_get(hash) {
		const obj = nsblob.cache.get(hash);
		if (!obj) return;
		nsblob.cache_keys.push(hash);
		return obj;
	}
	static cache_put(hash, obj, low_priority = false) {
		cache_size.set(nsblob.cache, nsblob.cache_size + obj.length);
		nsblob.cache.set(hash, obj);
		low_priority
			? nsblob.cache_keys.unshift(hash)
			: nsblob.cache_keys.push(hash);
		nsblob.gc(config.num.cache_size_limit);
	}
	static get cache_size() {
		return cache_size.get(nsblob.cache) || 0;
	}
	static set cache_size(max_size) {
		nsblob.gc(max_size);
	}
	static async store(data, file) {
		data || (data = '');
		if (data.length > file_size_limit) {
			throw new Error(
				`${file} is too large! ${data.length} > ${file_size_limit}`
			);
		}
		const blake = (0, blake_1.blake2sHex)(data);
		const prehash = nsblob.hashmap.getB2H(blake);
		if (prehash) return prehash;
		const prepromise = nsblob.promise_map.get(blake);
		if (prepromise) {
			return await prepromise;
		}
		const promise = new Promise((resolve, reject) => {
			socket.emit('blake2hash', blake).once(blake, (hash) => {
				if (hash) {
					nsblob.hashmap.setB2H(blake, hash);
					return resolve(hash);
				} else {
					const ref = `b_${blake}`;
					socket.emit('blob2hash', ref, data).once(ref, (hash) => {
						socket
							.emit('hash2blake', hash)
							.once(hash, (newblake) => {
								if (blake === newblake) {
									nsblob.hashmap.setB2H(blake, hash);
									return resolve(hash);
								} else {
									return reject(`nsblob: checksum mismatch`);
								}
							});
					});
				}
			});
		});
		nsblob.promise_map.set(blake, promise);
		return promise;
	}
	static async store_file(file, dir) {
		const stat = await fs_1.default.promises.stat(file);
		if (stat.size > file_size_limit)
			throw new Error(config.str.file_too_large);
		const data = await (0, serial_async_io_1.read)(file);
		return await nsblob.store(
			data,
			dir && path_1.default.relative(dir, file)
		);
	}
	static async store_dir(dir) {
		const read = await fs_1.default.promises.readdir(dir);
		const hashed = await Promise.all(
			read.map(async function fname(fname) {
				try {
					const pname = path_1.default.resolve(dir, fname);
					const stat = await fs_1.default.promises.stat(pname);
					if (stat.isDirectory()) {
						return [fname, await nsblob.store_dir(pname)];
					} else if (stat.isFile()) {
						return [fname, await nsblob.store_file(pname, dir)];
					} else {
						return [
							fname,
							await nsblob.store(config.str.str_not_a_file),
						];
					}
				} catch (error) {
					return [
						fname,
						await nsblob.store(config.str.str_internal_error),
					];
				}
			})
		);
		hashed.sort(([a], [b]) => (a < b ? -1 : 1));
		const ret = {};
		for (const [name, desc] of hashed) {
			ret[name] = desc;
		}
		return ret;
	}
	static async fetch(desc) {
		const from_cache = nsblob.cache_get(desc);
		if (from_cache) {
			return Buffer.from(from_cache);
		}
		return new Promise((resolve) => {
			socket.emit('request_blob', desc);
			socket.once(desc, (blob) => {
				nsblob.cache_put(desc, Buffer.from(blob));
				return resolve(Buffer.from(blob));
			});
		});
	}
	static async store_to_path(desc, fspath) {
		try {
			if (typeof desc === 'string') {
				const buf = await nsblob.fetch(desc);
				await (0, serial_async_io_1.write)(fspath, buf);
				return true;
			}
			if (!fs_1.default.existsSync(fspath)) {
				fs_1.default.mkdirSync(fspath, { recursive: true });
			}
			await Promise.all(
				Object.entries(desc).map(async ([name, desc]) => {
					let new_path = path_1.default.resolve(fspath, name);
					if (!new_path.includes(fspath))
						new_path = path_1.default.resolve(
							fspath,
							name
								.replace(/[^a-z0-9\-]+/gi, ' ')
								.trim()
								.replace(/[^a-z0-9\-]+/gi, '.')
						);
					return nsblob.store_to_path(desc, new_path);
				})
			);
			return true;
		} catch (error) {
			return false;
		}
	}
	static get config() {
		return config;
	}
	static get socket() {
		return socket;
	}
}
exports.nsblob = nsblob;
nsblob.cache = new Map();
nsblob.cache_keys = Array();
nsblob.hashmap = new hashmap_1.HashMap();
nsblob.promise_map = new Map();
const cache_size = new WeakMap([[nsblob.cache, 0]]);
exports.default = nsblob;
module.exports = nsblob;
Object.assign(nsblob, {
	default: nsblob,
	nsblob,
});
